{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About** : This notebook is used to infer models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../src/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import cv2\n",
    "import glob\n",
    "import json\n",
    "import torch\n",
    "import shutil\n",
    "import librosa\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.logger import Config\n",
    "from util.metrics import macro_auc\n",
    "from util.torch import load_model_weights\n",
    "\n",
    "from data.dataset import WaveInfDataset\n",
    "from data.preparation import prepare_data, prepare_folds\n",
    "from data.processing import create_target_path, ProgressParallel, get_load_librosa_save_h5py\n",
    "\n",
    "from model_zoo.models import define_model\n",
    "from inference.predict import predict\n",
    "\n",
    "from params import CLASSES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EVAL:\n",
    "    DATA_PATH = \"../input/train_audio/\"\n",
    "else:\n",
    "    DATA_PATH = \"../input/test_soundscapes/\"\n",
    "\n",
    "SAVE_FOLDER = \"../output/tmp/\"\n",
    "\n",
    "if os.path.exists(SAVE_FOLDER):\n",
    "    shutil.rmtree(SAVE_FOLDER)\n",
    "os.makedirs(SAVE_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "USE_FP16 = True\n",
    "NUM_WORKERS = 2\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "DURATION = 5\n",
    "SR = 32000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD = 0 if EVAL else \"fullfit_0\"\n",
    "\n",
    "EXP_FOLDERS = [\n",
    "    (\"../logs/2024-04-12/8/\", [FOLD]),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from util.logger import upload_to_kaggle\n",
    "\n",
    "# upload_to_kaggle(\n",
    "#     [f for f, _ in EXP_FOLDERS],\n",
    "#     directory=\"../output/dataset_1/\",\n",
    "#     dataset_name=\"BirdCLEF 2024 Weights 1\",\n",
    "#     update_folders=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EVAL:\n",
    "    df = pd.DataFrame({\"path\": glob.glob(DATA_PATH + \"*/*\")})\n",
    "    df[\"id\"] = df[\"path\"].apply(lambda x: x.split(\"/\")[-1][:-4])\n",
    "\n",
    "    folds = pd.read_csv('../input/folds_4.csv')\n",
    "    folds['id'] = folds['filename'].apply(lambda x: x.split('/')[-1][:-4])\n",
    "    df = df.merge(folds)\n",
    "    df = df[df['fold'] == 0].reset_index(drop=True)\n",
    "\n",
    "    df[\"primary_label\"] = df[\"path\"].apply(lambda x:  x.split('/')[-2])\n",
    "else:\n",
    "    df = pd.DataFrame({\"path\": glob.glob(DATA_PATH + \"*\")})\n",
    "    df[\"id\"] = df[\"path\"].apply(lambda x: x.split(\"/\")[-1][:-4])\n",
    "\n",
    "df[\"duration\"] = df[\"path\"].apply(lambda x: librosa.get_duration(path=x))\n",
    "\n",
    "df['slice'] = df['duration'].apply(lambda x: [(DURATION * i * SR, DURATION * (i + 1) * SR) for i in range(int(np.ceil(x / DURATION)))])\n",
    "df = df.explode(\"slice\")\n",
    "\n",
    "df[\"t_end\"] = DURATION\n",
    "df['t_end'] = df[[\"id\", \"t_end\"]].groupby(\"id\").cumsum()\n",
    "\n",
    "if EVAL:\n",
    "    df = df[df['t_end'] == 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "for exp_folder, folds in EXP_FOLDERS:\n",
    "    models_ = []\n",
    "    config = Config(json.load(open(exp_folder + \"config.json\", \"r\")))\n",
    "\n",
    "    model = define_model(\n",
    "        config.name,\n",
    "        config.melspec_config,\n",
    "        head=config.head,\n",
    "        aug_config=config.aug_config,\n",
    "        num_classes=config.num_classes,\n",
    "        n_channels=config.n_channels,\n",
    "        drop_rate=config.drop_rate,\n",
    "        drop_path_rate=config.drop_path_rate,\n",
    "        increase_stride=config.increase_stride,\n",
    "        verbose=True,\n",
    "        pretrained=False\n",
    "    )\n",
    "    model = model.to(DEVICE).eval()\n",
    "    \n",
    "    for fold in folds:\n",
    "        weights = exp_folder + f\"{config.name}_{fold}.pt\"\n",
    "        model = load_model_weights(model, weights, verbose=config.local_rank == 0)\n",
    "        models_.append(model)\n",
    "        \n",
    "    models.append(models_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = WaveInfDataset(\n",
    "    df,\n",
    "    normalize=config.normalize,\n",
    "    max_len=config.melspec_config[\"sample_rate\"] * config.duration,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predict(\n",
    "    model,\n",
    "    dataset,\n",
    "    config.loss_config,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    device=DEVICE,\n",
    "    use_fp16=USE_FP16,\n",
    "    num_workers=NUM_WORKERS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EVAL:\n",
    "    # dataset.use_secondary_labels = True\n",
    "    # y = dataset.get_targets()\n",
    "    # auc = macro_auc(y, preds)\n",
    "\n",
    "    auc = macro_auc(df[\"primary_label\"].values.tolist(), preds)\n",
    "    print(f'Fold 0 AUC: {auc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame((df[\"id\"] + \"_\" + df[\"t_end\"].astype(str)).values, columns=['row_id'])\n",
    "sub.loc[:, CLASSES] = preds\n",
    "# sub.to_csv('submission.csv', index=False)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done ! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "f7241b2af102f7e024509099765066b36197b195077f7bfac6e5bc041ba17c8c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
