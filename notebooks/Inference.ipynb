{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About** : This notebook is used to infer models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../src/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import cv2\n",
    "import glob\n",
    "import json\n",
    "import torch\n",
    "import shutil\n",
    "import librosa\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.logger import Config\n",
    "from util.metrics import macro_auc\n",
    "from util.torch import load_model_weights\n",
    "\n",
    "from data.dataset import WaveInfDataset\n",
    "from data.preparation import prepare_data, prepare_folds\n",
    "from data.processing import create_target_path, ProgressParallel, get_load_librosa_save_h5py\n",
    "\n",
    "from model_zoo.models import define_model\n",
    "from inference.predict import predict\n",
    "\n",
    "from params import CLASSES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EVAL:\n",
    "    DATA_PATH = \"../input/train_audio/\"\n",
    "else:\n",
    "    DATA_PATH = \"../input/unlabeled_soundscapes/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "USE_FP16 = True\n",
    "NUM_WORKERS = 2\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "DURATION = 5\n",
    "SR = 32000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD = 0 if EVAL else \"fullfit_0\"\n",
    "\n",
    "EXP_FOLDERS = [\n",
    "    # (\"../logs/2024-04-12/8/\", [FOLD]),   # LB 0.64 baseline\n",
    "    (\"../logs/2024-04-18/12/\", [FOLD]),  #\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from util.logger import upload_to_kaggle\n",
    "\n",
    "# upload_to_kaggle(\n",
    "#     [f for f, _ in EXP_FOLDERS],\n",
    "#     directory=\"../output/dataset_1/\",\n",
    "#     dataset_name=\"BirdCLEF 2024 Weights 1\",\n",
    "#     update_folders=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EVAL:\n",
    "    df = pd.DataFrame({\"path\": glob.glob(DATA_PATH + \"*/*\")})\n",
    "    df[\"id\"] = df[\"path\"].apply(lambda x: x.split(\"/\")[-1][:-4])\n",
    "\n",
    "    folds = pd.read_csv('../input/folds_4.csv')\n",
    "    folds['id'] = folds['filename'].apply(lambda x: x.split('/')[-1][:-4])\n",
    "    df = df.merge(folds)\n",
    "    df = df[df['fold'] == 0].reset_index(drop=True)\n",
    "\n",
    "    df[\"primary_label\"] = df[\"path\"].apply(lambda x:  x.split('/')[-2])\n",
    "else:\n",
    "    df = pd.DataFrame({\"path\": glob.glob(DATA_PATH + \"*\")})\n",
    "    df[\"id\"] = df[\"path\"].apply(lambda x: x.split(\"/\")[-1][:-4])\n",
    "\n",
    "df[\"duration\"] = df[\"path\"].apply(lambda x: librosa.get_duration(path=x))\n",
    "\n",
    "df['slice'] = df['duration'].apply(lambda x: [(DURATION * i * SR, DURATION * (i + 1) * SR) for i in range(int(np.ceil(x / DURATION)))])\n",
    "df = df.explode(\"slice\")\n",
    "\n",
    "df[\"t_end\"] = DURATION\n",
    "df['t_end'] = df[[\"id\", \"t_end\"]].groupby(\"id\").cumsum()\n",
    "\n",
    "if EVAL:\n",
    "    df = df[df['t_end'] == 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "for exp_folder, folds in EXP_FOLDERS:\n",
    "    models_ = []\n",
    "    config = Config(json.load(open(exp_folder + \"config.json\", \"r\")))\n",
    "\n",
    "    model = define_model(\n",
    "        config.name,\n",
    "        config.melspec_config,\n",
    "        head=config.head,\n",
    "        aug_config=config.aug_config,\n",
    "        num_classes=config.num_classes,\n",
    "        n_channels=config.n_channels,\n",
    "        drop_rate=config.drop_rate,\n",
    "        drop_path_rate=config.drop_path_rate,\n",
    "        increase_stride=config.increase_stride,\n",
    "        verbose=True,\n",
    "        pretrained=False\n",
    "    )\n",
    "    model = model.to(DEVICE).eval()\n",
    "    \n",
    "    for fold in folds:\n",
    "        weights = exp_folder + f\"{config.name}_{fold}.pt\"\n",
    "        model = load_model_weights(model, weights, verbose=config.local_rank == 0)\n",
    "        models_.append(model)\n",
    "        \n",
    "    models.append(models_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = WaveInfDataset(\n",
    "    df,\n",
    "    normalize=config.normalize,\n",
    "    max_len=config.melspec_config[\"sample_rate\"] * config.duration,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predict(\n",
    "    model,\n",
    "    dataset,\n",
    "    config.loss_config,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    device=DEVICE,\n",
    "    use_fp16=USE_FP16,\n",
    "    num_workers=NUM_WORKERS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EVAL:\n",
    "    auc = macro_auc(df[\"primary_label\"].values.tolist(), preds)\n",
    "    print(f'Fold 0 AUC: {auc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EVAL:\n",
    "    from data.preparation import prepare_data\n",
    "    from data.dataset import WaveDataset\n",
    "\n",
    "    df_ = prepare_data()\n",
    "    df_ = df_[df_['fold'] == 0].reset_index(drop=True)\n",
    "    df = df.merge(df_[[\"filename\", \"secondary_labels\"]], how=\"left\")\n",
    "    df['path_ft'] = df['path']\n",
    "    dataset = WaveDataset(df)\n",
    "\n",
    "    y, y_s = dataset.get_targets()\n",
    "\n",
    "    auc = macro_auc(y, preds)\n",
    "    print(f'Fold 0 AUC:\\t {auc:.3f}')\n",
    "    \n",
    "    auc = macro_auc(y_s, preds)\n",
    "    print(f'Fold 0 AUC_s:\\t {auc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not EVAL:\n",
    "    sub = pd.DataFrame((df[\"id\"] + \"_\" + df[\"t_end\"].astype(str)).values, columns=['row_id'])\n",
    "    sub.loc[:, CLASSES] = preds\n",
    "    sub.to_csv('../output/tmp/submission.csv', index=False)\n",
    "    sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('max_colwidth', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "from util.plots import display_audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Max per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_df = pd.DataFrame(sub.max()).T\n",
    "max_df = max_df[max_df.columns[1:]].astype(float)\n",
    "max_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(max_df.values[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Max per recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg = sub.copy()\n",
    "dfg['row_id'] = dfg['row_id'].apply(lambda x:x.split('_')[0])\n",
    "dfg = dfg.groupby('row_id').max()\n",
    "dfg = dfg.max(1)\n",
    "\n",
    "\n",
    "pd.DataFrame(dfg[dfg < 0.3]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg = sub.copy()\n",
    "\n",
    "dfg['row_id'] = dfg['row_id'].apply(lambda x:x.split('_')[0])\n",
    "\n",
    "dfg['max'] = dfg[dfg.columns[1:]].max(1)\n",
    "dfg_ = dfg[[\"row_id\", \"max\"]].groupby('row_id').max().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg = dfg.drop('max', axis=1).merge(dfg_, how=\"left\")\n",
    "\n",
    "dfg[CLASSES] = preds / dfg['max'].values[:, None]\n",
    "\n",
    "# pd.DataFrame(dfg).sort_values(\"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(dfg.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = np.load(EXP_FOLDERS[0][0] + \"pred_val_0.npy\")\n",
    "sns.histplot(val.max(-1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_ = \"1051136855\"\n",
    "id_ = \"1227419659\"\n",
    "\n",
    "df_id = sub[sub[\"row_id\"].apply(lambda x: id_ in x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(df_id[df_id.columns[1:]].max(1).values)\n",
    "plt.grid()\n",
    "plt.xticks([i for i in range(0, len(df_id), 2)], [f\"{i * 5 // 60}'{i * 5 % 60}\" for i in range(0, len(df_id), 2)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_audio(DATA_PATH + f\"{id_}.ogg\", duration=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done ! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "f7241b2af102f7e024509099765066b36197b195077f7bfac6e5bc041ba17c8c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
