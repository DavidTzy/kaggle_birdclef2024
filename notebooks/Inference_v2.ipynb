{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About** : This notebook is used to infer models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tviel/work/kaggle_birdclef_2024/src\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tviel/.local/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd ../src/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import cv2\n",
    "import glob\n",
    "import json\n",
    "import torch\n",
    "import shutil\n",
    "import joblib\n",
    "import librosa\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from scipy.special import expit\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.logger import Config\n",
    "from util.metrics import macro_auc\n",
    "from util.torch import load_model_weights\n",
    "\n",
    "from data.dataset import WaveInfDataset\n",
    "from data.preparation import prepare_data, prepare_folds\n",
    "from data.processing import create_target_path, ProgressParallel, get_load_librosa_save_h5py\n",
    "\n",
    "from model_zoo.models import define_model\n",
    "from inference.predict import predict\n",
    "\n",
    "from params import CLASSES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EVAL:\n",
    "    DATA_PATH = \"../input/train_audio/\"\n",
    "else:\n",
    "    DATA_PATH = \"../input/unlabeled_soundscapes/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 48\n",
    "USE_FP16 = True\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "DEVICE = \"cpu\" \n",
    "RUNTIME = \"openvino\"\n",
    "\n",
    "DURATION = 5\n",
    "SR = 32000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD = 0 if EVAL else \"fullfit_0\"\n",
    "\n",
    "EXP_FOLDERS = [\n",
    "    # (\"../logs/2024-04-12/8/\", [FOLD]),   # LB 0.64 baseline\n",
    "    # (\"../logs/2024-04-18/12/\", [FOLD]),  #\n",
    "    # (\"../logs/2024-04-18/15/\", [FOLD]),  #\n",
    "    # (\"../logs/2024-04-19/4/\", [FOLD]),  # Change norm, sampling\n",
    "    # (\"../logs/2024-04-19/5/\", [FOLD]),  # d=15s\n",
    "    # (\"../logs/2024-04-19/7/\", [FOLD]),  # minmaxnorm, sampling, nocall, less mix\n",
    "    # (\"../logs/2024-04-19/8/\", [FOLD]),  # minmaxnorm, no sampling, nocall, less mix no add\n",
    "    # (\"../logs/2024-04-19/10/\", [FOLD]),  # minmaxnorm more mix more aug\n",
    "    # (\"../logs/2024-04-29/2/\", [FOLD]),  # minmaxnorm fixed crop\n",
    "    # (\"../logs/2024-04-29/4/\", [FOLD]),  # minmaxnorm fixed crop 20s selfmix\n",
    "    # (\"../logs/2024-04-29/6/\", [FOLD]),  # minmaxnorm fixed crop no_xc selfmix\n",
    "    # (\"../logs/2024-04-29/7/\", [FOLD]),  # minmaxnorm fixed crop no_xc selfmix focal_bce ousmk\n",
    "    # (\"../logs/2024-04-30/0/\", [FOLD]),  # minmaxnorm selfmix focal_bce ousmk\n",
    "    # (\"../logs/2024-04-30/1/\", [FOLD]),  # minmaxnorm selfmix focal_bce ousmk++\n",
    "    # (\"../logs/2024-04-30/3/\", [FOLD]),  # minmaxnorm selfmix focal_bce no_xc more mix\n",
    "    # (\"../logs/2024-04-30/4/\", [FOLD]),  # minmaxnorm selfmix bce no_xc ousmk^\n",
    "    # (\"../logs/2024-05-02/0/\", [FOLD]),  # selfmix focal_bce ousmk + dedup, new melspec params, start-end sampling\n",
    "    (\"../logs/2024-05-02/15/\", [FOLD]),  # no selfmix focal_bce ousmk + 2nd mask, new melspec params, start-end sampling\n",
    "    (\"../logs/2024-05-04/4/\", [FOLD]),  # no selfmix bce + 2nd mask, new melspec params, start-end sampling + fewer epochs, wd AdamW\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from util.logger import upload_to_kaggle\n",
    "\n",
    "# upload_to_kaggle(\n",
    "#     [f for f, _ in EXP_FOLDERS],\n",
    "#     directory=\"../output/dataset_1/\",\n",
    "#     dataset_name=\"BirdCLEF 2024 Weights 1\",\n",
    "#     update_folders=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EVAL:\n",
    "    df = pd.DataFrame({\"path\": glob.glob(DATA_PATH + \"*/*\")})\n",
    "    df[\"id\"] = df[\"path\"].apply(lambda x: x.split(\"/\")[-1][:-4])\n",
    "\n",
    "    folds = pd.read_csv('../input/folds_4.csv')\n",
    "    folds['id'] = folds['filename'].apply(lambda x: x.split('/')[-1][:-4])\n",
    "    df = df.merge(folds)\n",
    "    df = df[df['fold'] == 0].reset_index(drop=True)\n",
    "\n",
    "    df[\"primary_label\"] = df[\"path\"].apply(lambda x:  x.split('/')[-2])\n",
    "else:\n",
    "    df = pd.DataFrame({\"path\": glob.glob(DATA_PATH + \"*\")})\n",
    "    df[\"id\"] = df[\"path\"].apply(lambda x: x.split(\"/\")[-1][:-4])\n",
    "    \n",
    "    df[\"duration\"] = df[\"path\"].apply(lambda x: librosa.get_duration(path=x))\n",
    "    df = df[df[\"duration\"] == 240].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>id</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../input/unlabeled_soundscapes/184575141.ogg</td>\n",
       "      <td>184575141</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../input/unlabeled_soundscapes/1542255759.ogg</td>\n",
       "      <td>1542255759</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../input/unlabeled_soundscapes/1976786596.ogg</td>\n",
       "      <td>1976786596</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../input/unlabeled_soundscapes/106748716.ogg</td>\n",
       "      <td>106748716</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../input/unlabeled_soundscapes/523220948.ogg</td>\n",
       "      <td>523220948</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            path          id  duration\n",
       "0   ../input/unlabeled_soundscapes/184575141.ogg   184575141     240.0\n",
       "1  ../input/unlabeled_soundscapes/1542255759.ogg  1542255759     240.0\n",
       "2  ../input/unlabeled_soundscapes/1976786596.ogg  1976786596     240.0\n",
       "3   ../input/unlabeled_soundscapes/106748716.ogg   106748716     240.0\n",
       "4   ../input/unlabeled_soundscapes/523220948.ogg   523220948     240.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -> Loading encoder weights from ../logs/2024-05-02/15/tf_efficientnetv2_s_fullfit_0.pt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "\n",
    "for exp_folder, folds in EXP_FOLDERS:\n",
    "    models_ = []\n",
    "    config = Config(json.load(open(exp_folder + \"config.json\", \"r\")))\n",
    "\n",
    "    model = define_model(\n",
    "        config.name,\n",
    "        config.melspec_config,\n",
    "        head=config.head,\n",
    "        aug_config=config.aug_config,\n",
    "        num_classes=config.num_classes,\n",
    "        n_channels=config.n_channels,\n",
    "        drop_rate=config.drop_rate,\n",
    "        drop_path_rate=config.drop_path_rate,\n",
    "        # exportable=True,\n",
    "        verbose=True,\n",
    "        pretrained=False\n",
    "    )\n",
    "    model = model.to(DEVICE).eval()\n",
    "    \n",
    "    for fold in folds:\n",
    "        weights = exp_folder + f\"{config.name}_{fold}.pt\"\n",
    "        model = load_model_weights(model, weights, verbose=config.local_rank == 0)\n",
    "        models_.append(model)\n",
    "        \n",
    "    models.append(models_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 1280, 4, 10)\n"
     ]
    }
   ],
   "source": [
    "if RUNTIME != \"torch\":\n",
    "    import onnx\n",
    "    import onnxruntime as ort\n",
    "    from onnxconverter_common import float16\n",
    "\n",
    "    def infer_onnx(ort_session, x, output_names=[\"output\"], input_name=\"x\"):\n",
    "        x = ort_session.run(output_names, {input_name: x.numpy()})[0]\n",
    "        return x\n",
    "\n",
    "    input_names = ['x']\n",
    "    output_names = ['output']\n",
    "\n",
    "    input_tensor = torch.randn(\n",
    "        BATCH_SIZE,\n",
    "        1,\n",
    "        config.melspec_config['n_mels'],\n",
    "        313 if config.melspec_config['hop_length'] == 512 else 224\n",
    "    )\n",
    "\n",
    "    onnx_ckpt_list = []\n",
    "    for models_ in models:\n",
    "        for i, model in enumerate(models_):\n",
    "            torch.onnx.export(\n",
    "                model.encoder,\n",
    "                input_tensor,\n",
    "                f\"model_{i}.onnx\",\n",
    "                verbose=False,\n",
    "                input_names=input_names,\n",
    "                output_names=output_names,\n",
    "                dynamic_axes={\"x\": [0]}\n",
    "            )\n",
    "            onnx_ckpt_list.append(f\"model_{i}.onnx\")\n",
    "\n",
    "\n",
    "    ort_sessions = []\n",
    "    for i in range(len(models)):\n",
    "        onnx_model = onnx.load(f\"model_{i}.onnx\")\n",
    "        # onnx_model = float16.convert_float_to_float16(onnx_model)\n",
    "        # onnx.save(onnx_model, f\"model_{i}.onnx\")\n",
    "        onnx.checker.check_model(onnx_model)\n",
    "        ort_session = ort.InferenceSession(f\"model_{i}.onnx\")\n",
    "        ort_sessions.append(ort_session)\n",
    "        \n",
    "    ort_session_2 = ort_sessions[0]\n",
    "    out = ort_session_2.run(output_names, {input_names[0] : input_tensor.numpy()})  # .astype(np.float16)\n",
    "    print(out[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ INFO ] Generated IR will be compressed to FP16. If you get lower accuracy, please consider disabling compression explicitly by adding argument --compress_to_fp16=False.\n",
      "Find more information about compression to FP16 at https://docs.openvino.ai/2023.0/openvino_docs_MO_DG_FP16_Compression.html\n",
      "[ INFO ] MO command line tool is considered as the legacy conversion API as of OpenVINO 2023.2 release. Please use OpenVINO Model Converter (OVC). OVC represents a lightweight alternative of MO and provides simplified model conversion API. \n",
      "Find more information about transition from MO to OVC at https://docs.openvino.ai/2023.2/openvino_docs_OV_Converter_UG_prepare_model_convert_model_MO_OVC_transition.html\n",
      "[ SUCCESS ] Generated IR version 11 model.\n",
      "[ SUCCESS ] XML file: /home/tviel/work/kaggle_birdclef_2024/src/model_0.xml\n",
      "[ SUCCESS ] BIN file: /home/tviel/work/kaggle_birdclef_2024/src/model_0.bin\n"
     ]
    }
   ],
   "source": [
    "if RUNTIME == \"openvino\":\n",
    "    !mo --input_model model_0.onnx # --compress_to_fp16=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUNTIME == \"openvino\":\n",
    "    import openvino.runtime as ov\n",
    "    core = ov.Core()\n",
    "    openvino_model = core.read_model(model='model_0.xml')\n",
    "    compiled_model = core.compile_model(openvino_model, device_name=\"CPU\")\n",
    "    infer_request = compiled_model.create_infer_request()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUNTIME = \"openvino\"  # torch openvino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sample(path):\n",
    "    wave, sr = librosa.load(path, sr=SR)\n",
    "\n",
    "    if EVAL:\n",
    "        if len(wave) > SR * DURATION:\n",
    "            wave = wave[:SR * DURATION][None]\n",
    "        else:\n",
    "            wave = np.pad(wave, (0, SR * DURATION - len(wave)))[None]\n",
    "    else:\n",
    "        wave = wave.reshape(-1, SR * DURATION)\n",
    "\n",
    "    if config.normalize:\n",
    "        wave = np.array([librosa.util.normalize(w) for w in wave])\n",
    "\n",
    "    wave = torch.from_numpy(wave)\n",
    "    return wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_sample(wave):\n",
    "    if isinstance(wave, str):\n",
    "        wave = load_sample(wave)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        with torch.cuda.amp.autocast(enabled=False):\n",
    "            melspec = model.ft_extractor(wave)[0].unsqueeze(1)\n",
    "\n",
    "        # y_pred = torch.zeros((48, 182))\n",
    "\n",
    "        if RUNTIME == \"openvino\":\n",
    "            fts = infer_request.infer(inputs=[melspec.numpy()])[\"output\"]\n",
    "            y_pred = model.get_logits(torch.from_numpy(fts))\n",
    "        elif RUNTIME == \"onnx\":\n",
    "            fts = infer_onnx(ort_session, melspec)\n",
    "            y_pred = model.get_logits(torch.from_numpy(fts))\n",
    "        else:\n",
    "            with torch.cuda.amp.autocast(enabled=USE_FP16):\n",
    "                fts = model.encoder(melspec)\n",
    "                y_pred = model.get_logits(fts)\n",
    "        y_pred = y_pred.detach().numpy()\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"path\"].apply(lambda x: \"1872382287\" in x)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1955.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "waves = joblib.Parallel(n_jobs=4)(  # , backend='loky'\n",
    "    joblib.delayed(load_sample)(path) for path in tqdm(df[\"path\"].values)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'infer_request' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m all_preds \u001b[38;5;241m=\u001b[39m [infer_sample(wave) \u001b[38;5;28;01mfor\u001b[39;00m wave \u001b[38;5;129;01min\u001b[39;00m tqdm(waves)]  \u001b[38;5;66;03m# Torch - 2:46\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[39], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m all_preds \u001b[38;5;241m=\u001b[39m [\u001b[43minfer_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwave\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m wave \u001b[38;5;129;01min\u001b[39;00m tqdm(waves)]  \u001b[38;5;66;03m# Torch - 2:46\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[35], line 12\u001b[0m, in \u001b[0;36minfer_sample\u001b[0;34m(wave)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# y_pred = torch.zeros((48, 182))\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RUNTIME \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenvino\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 12\u001b[0m     fts \u001b[38;5;241m=\u001b[39m \u001b[43minfer_request\u001b[49m\u001b[38;5;241m.\u001b[39minfer(inputs\u001b[38;5;241m=\u001b[39m[melspec\u001b[38;5;241m.\u001b[39mnumpy()])[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     13\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_logits(torch\u001b[38;5;241m.\u001b[39mfrom_numpy(fts))\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m RUNTIME \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monnx\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'infer_request' is not defined"
     ]
    }
   ],
   "source": [
    "all_preds = [infer_sample(wave) for wave in tqdm(waves)]  # Torch - 2:46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b0359fe55a24cc8a188767811bba13f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_preds = [infer_sample(wave) for wave in tqdm(waves)]  # OV FP16 - 2:11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0a29e949c7f477ca74bf98ecf125947",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_preds = [infer_sample(wave) for wave in tqdm(waves)]  # OV FP32 - 2:11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9965c3cf6b8342b5ae9dd25c8c3a2267",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_preds = [infer_sample(path) for path in tqdm(df[\"path\"].values)]  # no model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "906386b1a9bd49da8a650f5f637bfb1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_preds = [infer_sample(path) for path in tqdm(df[\"path\"].values)]  # no melspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad3baf92593c43718af01a54343ea557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_preds = [infer_sample(path) for path in tqdm(df[\"path\"].values)]  # only load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 749.25it/s]\n"
     ]
    }
   ],
   "source": [
    "inference_rows = []\n",
    "for idx in tqdm(range(len(df))):\n",
    "\n",
    "    y_pred = all_preds[idx]\n",
    "    preds = expit(y_pred)\n",
    "\n",
    "    for t, pred in enumerate(preds):\n",
    "        predictions = dict([(l, p) for l, p in zip(CLASSES, pred)])\n",
    "        inference_rows.append(\n",
    "            {'row_id': f'{df.id[idx]}_{(t + 1) * 5}' } | predictions\n",
    "        )\n",
    "\n",
    "sub = pd.DataFrame(inference_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>asbfly</th>\n",
       "      <th>ashdro1</th>\n",
       "      <th>ashpri1</th>\n",
       "      <th>ashwoo2</th>\n",
       "      <th>asikoe2</th>\n",
       "      <th>asiope1</th>\n",
       "      <th>aspfly1</th>\n",
       "      <th>aspswi1</th>\n",
       "      <th>barfly1</th>\n",
       "      <th>...</th>\n",
       "      <th>whbwoo2</th>\n",
       "      <th>whcbar1</th>\n",
       "      <th>whiter2</th>\n",
       "      <th>whrmun</th>\n",
       "      <th>whtkin2</th>\n",
       "      <th>woosan</th>\n",
       "      <th>wynlau1</th>\n",
       "      <th>yebbab1</th>\n",
       "      <th>yebbul3</th>\n",
       "      <th>zitcis1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1872382287_5</td>\n",
       "      <td>0.002922</td>\n",
       "      <td>0.129089</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.000560</td>\n",
       "      <td>0.003429</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.001513</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002118</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>0.002263</td>\n",
       "      <td>0.008572</td>\n",
       "      <td>0.001041</td>\n",
       "      <td>0.000571</td>\n",
       "      <td>0.011071</td>\n",
       "      <td>0.001834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1872382287_10</td>\n",
       "      <td>0.003955</td>\n",
       "      <td>0.032630</td>\n",
       "      <td>0.000850</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.003024</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005962</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>0.003496</td>\n",
       "      <td>0.002194</td>\n",
       "      <td>0.005088</td>\n",
       "      <td>0.024762</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.001841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1872382287_15</td>\n",
       "      <td>0.003516</td>\n",
       "      <td>0.066223</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.004243</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.001076</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002762</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>0.001434</td>\n",
       "      <td>0.001074</td>\n",
       "      <td>0.015218</td>\n",
       "      <td>0.030678</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.001982</td>\n",
       "      <td>0.001014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1872382287_20</td>\n",
       "      <td>0.002976</td>\n",
       "      <td>0.003322</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>0.000731</td>\n",
       "      <td>0.013947</td>\n",
       "      <td>0.000532</td>\n",
       "      <td>0.001118</td>\n",
       "      <td>0.001784</td>\n",
       "      <td>0.002137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008639</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.003597</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>0.003911</td>\n",
       "      <td>0.031162</td>\n",
       "      <td>0.001118</td>\n",
       "      <td>0.002764</td>\n",
       "      <td>0.001228</td>\n",
       "      <td>0.002651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1872382287_25</td>\n",
       "      <td>0.003274</td>\n",
       "      <td>0.065591</td>\n",
       "      <td>0.000857</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.007834</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.002124</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002330</td>\n",
       "      <td>0.001801</td>\n",
       "      <td>0.003665</td>\n",
       "      <td>0.003726</td>\n",
       "      <td>0.005863</td>\n",
       "      <td>0.030730</td>\n",
       "      <td>0.001214</td>\n",
       "      <td>0.001157</td>\n",
       "      <td>0.001222</td>\n",
       "      <td>0.005482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 183 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          row_id    asbfly   ashdro1   ashpri1   ashwoo2   asikoe2   asiope1  \\\n",
       "0   1872382287_5  0.002922  0.129089  0.000390  0.000560  0.003429  0.000327   \n",
       "1  1872382287_10  0.003955  0.032630  0.000850  0.000193  0.003024  0.000204   \n",
       "2  1872382287_15  0.003516  0.066223  0.000459  0.000075  0.004243  0.000278   \n",
       "3  1872382287_20  0.002976  0.003322  0.007874  0.000731  0.013947  0.000532   \n",
       "4  1872382287_25  0.003274  0.065591  0.000857  0.000244  0.007834  0.000572   \n",
       "\n",
       "    aspfly1   aspswi1   barfly1  ...   whbwoo2   whcbar1   whiter2    whrmun  \\\n",
       "0  0.001513  0.000135  0.000581  ...  0.002118  0.000214  0.000852  0.000594   \n",
       "1  0.000830  0.000279  0.000449  ...  0.005962  0.000296  0.003496  0.002194   \n",
       "2  0.001076  0.000177  0.000183  ...  0.002762  0.000901  0.001434  0.001074   \n",
       "3  0.001118  0.001784  0.002137  ...  0.008639  0.000393  0.003597  0.001014   \n",
       "4  0.002124  0.000531  0.000317  ...  0.002330  0.001801  0.003665  0.003726   \n",
       "\n",
       "    whtkin2    woosan   wynlau1   yebbab1   yebbul3   zitcis1  \n",
       "0  0.002263  0.008572  0.001041  0.000571  0.011071  0.001834  \n",
       "1  0.005088  0.024762  0.000241  0.000161  0.000457  0.001841  \n",
       "2  0.015218  0.030678  0.000313  0.000496  0.001982  0.001014  \n",
       "3  0.003911  0.031162  0.001118  0.002764  0.001228  0.002651  \n",
       "4  0.005863  0.030730  0.001214  0.001157  0.001222  0.005482  \n",
       "\n",
       "[5 rows x 183 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 AUC: 0.98153\n"
     ]
    }
   ],
   "source": [
    "if EVAL:\n",
    "    preds = sub[CLASSES].values\n",
    "    auc = macro_auc(df[\"primary_label\"].values.tolist(), preds)\n",
    "    print(f'Fold 0 AUC: {auc:.5f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "f7241b2af102f7e024509099765066b36197b195077f7bfac6e5bc041ba17c8c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
