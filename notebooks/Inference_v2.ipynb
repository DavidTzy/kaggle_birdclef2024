{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About** : This notebook is used to infer models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tviel/work/kaggle_birdclef_2024/src\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tviel/.local/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd ../src/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0+cu121\n",
      "NVIDIA RTX 6000 Ada Generation\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "print(torch.__version__)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "device = torch.cuda.get_device_name(0)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import cv2\n",
    "import glob\n",
    "import json\n",
    "import torch\n",
    "import shutil\n",
    "import joblib\n",
    "import librosa\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.special import expit\n",
    "from scipy.stats import pearsonr\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=UserWarning)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option(\"display.precision\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.logger import Config\n",
    "from util.metrics import macro_auc, get_correlation_matrix\n",
    "from util.torch import load_model_weights\n",
    "from util.plots import plot_corr\n",
    "\n",
    "from data.preparation import prepare_data, prepare_folds\n",
    "from model_zoo.models import define_model\n",
    "from inference.predict import infer_onnx, load_sample, infer_sample\n",
    "from params import CLASSES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EVAL:\n",
    "    DATA_PATH = \"../input/train_audio/\"\n",
    "else:\n",
    "    DATA_PATH = \"../input/unlabeled_soundscapes/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 48\n",
    "USE_FP16 = True\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "DEVICE = \"cuda\"\n",
    "\n",
    "DURATION = 5\n",
    "SR = 32000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD = 0 if EVAL else \"fullfit_0\"\n",
    "\n",
    "EXP_FOLDERS = [\n",
    "    # ROUND 0 - PL2 Mixup only\n",
    "    # (\"../logs/2024-05-16/2/\", [f\"{i}\" for i in range(4)], \"torch\"),   # vit-b0\n",
    "    # (\"../logs/2024-05-16/3/\", [f\"{i}\" for i in range(4)], \"torch\"),   # vit-b1\n",
    "    # (\"../logs/2024-05-16/4/\", [f\"{i}\" for i in range(4)], \"torch\"),   # mixnet\n",
    "    # (\"../logs/2024-05-16/5/\", [f\"{i}\" for i in range(4)], \"torch\"),   # mobilenet\n",
    "    # (\"../logs/2024-05-16/6/\", [f\"{i}\" for i in range(4)], \"torch\"),   # mnasnet\n",
    "    # (\"../logs/2024-05-16/7/\", [f\"{i}\" for i in range(4)], \"torch\"),   # b0\n",
    "    # (\"../logs/2024-05-16/8/\", [f\"{i}\" for i in range(4)], \"torch\"),   # tinynet\n",
    "    # (\"../logs/2024-05-16/9/\", [f\"{i}\" for i in range(4)], \"torch\"),   # b0-v2\n",
    "\n",
    "    # ROUND 1 - PL2\n",
    "    # (\"../logs/2024-05-16/12/\", [f\"{i}\" for i in range(4)], \"torch\"),   # vit-b0 PL2 no augs               0.71\n",
    "    # (\"../logs/2024-05-16/14/\", [f\"{i}\" for i in range(4)], \"torch\"),   # vit-b0 PL2 no overfitnoisy       0.71\n",
    "    # (\"../logs/2024-05-17/2/\", [f\"{i}\" for i in range(4)], \"torch\"),   # mobilenetv2 PL2 no augs           0.69\n",
    "    # (\"../logs/2024-05-17/3/\", [f\"{i}\" for i in range(4)], \"torch\"),   # mnasnet PL2 no augs               0.70\n",
    "    # (\"../logs/2024-05-18/0/\", [f\"{i}\" for i in range(4)], \"torch\"),   # effvitm2 PL2 no augs              0.69\n",
    "    # (\"../logs/2024-05-18/1/\", [f\"{i}\" for i in range(4)], \"torch\"),   # effvitm3 PL2 no augs              0.70\n",
    "    # (\"../logs/2024-05-18/4/\", [f\"{i}\" for i in range(4)], \"torch\"),   # mnasnet PL2 no augs 20 eps        0.67\n",
    "    # (\"../logs/2024-05-18/8/\", [f\"{i}\" for i in range(4)], \"torch\"),   # mobilenetv3_s PL2 no augs         0.?\n",
    "    # (\"../logs/2024-05-19/0/\", [f\"{i}\" for i in range(4)], \"torch\"),   # efficientnet_lite0 PL2 no augs    0.70\n",
    "    # (\"../logs/2024-05-19/1/\", [f\"{i}\" for i in range(4)], \"torch\"),   # effvitm4 PL2 no augs              0.?\n",
    "    # (\"../logs/2024-05-19/2/\", [f\"{i}\" for i in range(4)], \"torch\"),   # effvitm5 PL2 no augs              0.69\n",
    "    # (\"../logs/2024-05-19/6/\", [f\"{i}\" for i in range(4)], \"torch\"),   # effvitm3 PL2 no augs 16/48 pl     0.70\n",
    "    # (\"../logs/2024-05-19/9/\", [f\"{i}\" for i in range(4)], \"torch\"),   # regnety_002 PL2 no augs           0.?\n",
    "    # (\"../logs/2024-05-19/10/\", [f\"{i}\" for i in range(4)], \"torch\"),  # regnety_004 PL2 no augs           0.?\n",
    "    # (\"../logs/2024-05-20/1/\", [f\"{i}\" for i in range(4)], \"torch\"),   # lcnet_100 PL2 no augs             0.?\n",
    "    # (\"../logs/2024-05-20/2/\", [f\"{i}\" for i in range(4)], \"torch\"),   # mobilenetv3_lm PL2 no augs        0.?\n",
    "    # (\"../logs/2024-05-20/5/\", [f\"{i}\" for i in range(4)], \"torch\"),   # repghostnet_100 PL2 no augs       0.70\n",
    "\n",
    "    # Round 2 PL2\n",
    "    # (\"../logs/2024-05-20/7/\", [f\"{i}\" for i in range(4)], \"torch\"),   # mnasnet PL2 no augs round 2       0.70\n",
    "\n",
    "    # Tweak Mnasnet\n",
    "    # (\"../logs/2024-05-21/1/\", [f\"{i}\" for i in range(4)], \"torch\"),   # mnasnet PL2 no augs xc                      0.70\n",
    "    # (\"../logs/2024-05-21/3/\", [f\"{i}\" for i in range(4)], \"torch\"),   # mnasnet PL2 no augs random sampling         0.68\n",
    "    # (\"../logs/2024-05-21/4/\", [f\"{i}\" for i in range(4)], \"torch\"),   # mnasnet PL2 no augs xc start sampling       0.71\n",
    "    # (\"../logs/2024-05-22/1/\", [f\"{i}\" for i in range(4)], \"torch\"),   # mnasnet PL2 no augs xc start sampling sec   0.??\n",
    "\n",
    "    # ROUND 0 - PL3\n",
    "    # (\"../logs/2024-05-22/2/\", [f\"{i}\" for i in range(4)], \"torch\"),  # efficientvit_b0\n",
    "    # (\"../logs/2024-05-22/3/\", [f\"{i}\" for i in range(4)], \"torch\"),  # efficientvit_b1\n",
    "    # (\"../logs/2024-05-22/4/\", [f\"{i}\" for i in range(4)], \"torch\"),  # efficientvit_m3\n",
    "    # (\"../logs/2024-05-22/5/\", [f\"{i}\" for i in range(4)], \"torch\"),  # mnasnet_100\n",
    "    # (\"../logs/2024-05-22/6/\", [f\"{i}\" for i in range(4)], \"torch\"),  # efficientnet_b0\n",
    "    # (\"../logs/2024-05-22/7/\", [f\"{i}\" for i in range(4)], \"torch\"),  # mobilenetv3_lm\n",
    "\n",
    "    # (\"../logs/2024-05-23/1/\", [f\"{i}\" for i in range(4)], \"torch\"),  # mobilenetv3_lm\n",
    "    # (\"../logs/2024-05-23/4/\", [f\"{i}\" for i in range(4)], \"torch\"),  # efficientvit_m3\n",
    "\n",
    "    # # ROUND 1 - PL3\n",
    "    # (\"../logs/2024-05-22/8/\", [f\"{i}\" for i in range(4)], \"torch\"),  # PL3 efficientvit_b0\n",
    "    # (\"../logs/2024-05-22/9/\", [f\"{i}\" for i in range(4)], \"torch\"),  # PL3 mnasnet\n",
    "\n",
    "\n",
    "    # (\"../logs/2024-05-23/5/\", [f\"{i}\" for i in range(4)], \"torch\"),  # PL2.5 efficientvit_b0\n",
    "    # (\"../logs/2024-05-23/6/\", [f\"{i}\" for i in range(4)], \"torch\"),  # PL2.5 mnasnet\n",
    "    # (\"../logs/2024-05-23/8/\", [f\"{i}\" for i in range(4)], \"torch\"),  # PL2.5 mnasnet more epochs\n",
    "    # (\"../logs/2024-05-24/0/\", [f\"{i}\" for i in range(4)], \"torch\"),  # PL2.5 efficientvit_b0 more epochs\n",
    "\n",
    "\n",
    "    # (\"../logs/2024-06-02/1/\", [f\"{i}\" for i in range(4)], \"torch\"),  # PL2.5 efficientvit_b0 more epochs less reg old comp\n",
    "    # (\"../logs/2024-06-03/0/\", [f\"{i}\" for i in range(4)], \"torch\"),  # PL2.5 mnasnet more epochs nodrop old comp lower lr\n",
    "\n",
    "    # (\"../logs/2024-06-03/3/\", [f\"{i}\" for i in range(4)], \"torch\"),  # PL2.5 efficientvit_b0 more epochs old comp mixup\n",
    "    # (\"../logs/2024-06-03/4/\", [f\"{i}\" for i in range(4)], \"torch\"),  # PL2.5 mnasnet more epochs old comp mixup\n",
    "    \n",
    "    # (\"../logs/2024-06-04/2/\", [f\"{i}\" for i in range(4)], \"torch\"),  # PL2.5 efficientvit_b0 more epochs old comp mixup no rating=1 dedup  no up\n",
    "    # (\"../logs/2024-06-04/3/\", [f\"{i}\" for i in range(4)], \"torch\"),  # PL2.5 mnasnet more epochs old comp mixup no rating=1 dedup  no up\n",
    "\n",
    "    # (\"../logs/2024-06-05/2/\", [f\"{i}\" for i in range(4)], \"torch\"),  # PL2.5 efficientvit_b0 more epochs old comp mixup no rating=1 dedup more pl\n",
    "    # (\"../logs/2024-06-05/3/\", [f\"{i}\" for i in range(4)], \"torch\"),  # PL2.5 mnasnet more epochs old comp mixup no rating=1 dedup more pl \n",
    "\n",
    "    # (\"../logs/2024-06-05/4/\", [f\"{i}\" for i in range(4)], \"torch\"),  # PL2.5 efficientvit_b0 more epochs old comp more mixup no rating=1 dedup no up\n",
    "    # (\"../logs/2024-06-06/0/\", [f\"{i}\" for i in range(4)], \"torch\"),  # PL2.5 mnasnet more epochs old comp more mixup no rating=1 dedup no up \n",
    "\n",
    "\n",
    "    # # Round 0 - PL4\n",
    "    # (\"../logs/2024-06-06/1/\", [f\"{i}\" for i in range(4)], \"torch\"),  # efficientvit_b0\n",
    "    # (\"../logs/2024-06-06/2/\", [f\"{i}\" for i in range(4)], \"torch\"),  # efficientvit_b1\n",
    "    # (\"../logs/2024-06-06/3/\", [f\"{i}\" for i in range(4)], \"torch\"),  # efficientvit_m3\n",
    "    # (\"../logs/2024-06-06/4/\", [f\"{i}\" for i in range(4)], \"torch\"),  # mnasnet_100\n",
    "    # (\"../logs/2024-06-06/5/\", [f\"{i}\" for i in range(4)], \"torch\"),  # tf_efficientnet_b0\n",
    "    # (\"../logs/2024-06-06/6/\", [f\"{i}\" for i in range(4)], \"torch\"),  # tf_mobilenetv3_large_minimal_100\n",
    "    # (\"../logs/2024-06-06/7/\", [f\"{i}\" for i in range(4)], \"torch\"),  # tf_efficientnetv2_b0\n",
    "    # (\"../logs/2024-06-06/8/\", [f\"{i}\" for i in range(4)], \"torch\"),  # tinynet_b\n",
    "    # (\"../logs/2024-06-06/9/\", [f\"{i}\" for i in range(4)], \"torch\"),  # mixnet_s\n",
    "\n",
    "\n",
    "    # (\"../logs/2024-06-06/10/\", [f\"{i}\" for i in range(4)], \"torch\"),  # PL4 efficientvit_b0 more epochs old comp mixup no rating=1 dedup no up\n",
    "    # (\"../logs/2024-06-07/0/\", [f\"{i}\" for i in range(4)], \"torch\"),  # PL4 mnasnet more epochs old comp mixup no rating=1 dedup no up \n",
    "\n",
    "    \n",
    "    # # Round 0 - PL5\n",
    "    # (\"../logs/2024-06-07/1/\", [f\"{i}\" for i in range(4)], \"torch\"),  # efficientvit_b0\n",
    "    # (\"../logs/2024-06-07/2/\", [f\"{i}\" for i in range(4)], \"torch\"),  # efficientvit_b1\n",
    "    # (\"../logs/2024-06-07/3/\", [f\"{i}\" for i in range(4)], \"torch\"),  # efficientvit_m3\n",
    "    # (\"../logs/2024-06-07/4/\", [f\"{i}\" for i in range(4)], \"torch\"),  # mnasnet_100\n",
    "    # (\"../logs/2024-06-07/5/\", [f\"{i}\" for i in range(4)], \"torch\"),  # tf_efficientnet_b0\n",
    "    # (\"../logs/2024-06-07/6/\", [f\"{i}\" for i in range(4)], \"torch\"),  # tf_mobilenetv3_large_minimal_100\n",
    "    # (\"../logs/2024-06-07/7/\", [f\"{i}\" for i in range(4)], \"torch\"),  # tf_efficientnetv2_b0\n",
    "    # (\"../logs/2024-06-07/8/\", [f\"{i}\" for i in range(4)], \"torch\"),  # tinynet_b\n",
    "    # (\"../logs/2024-06-07/9/\", [f\"{i}\" for i in range(4)], \"torch\"),  # mixnet_s\n",
    "\n",
    "    (\"../logs/2024-06-07/10/\", [f\"{i}\" for i in range(4)], \"torch\"),  # PL5 efficientvit_b0 more epochs old comp mixup no rating=1 dedup no up\n",
    "    (\"../logs/2024-06-07/11/\", [f\"{i}\" for i in range(4)], \"torch\"),  # PL5 mnasnet more epochs old comp mixup no rating=1 dedup no up\n",
    "\n",
    "    # (\"../logs/2024-06-09/10/\", [f\"fullfit_{i}\" for i in range(3)], \"torch\"),  # effvit aves\n",
    "    # (\"../logs/2024-06-09/11/\", [f\"fullfit_{i}\" for i in range(3)], \"torch\"),  # mnasnet aves\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from util.logger import upload_to_kaggle\n",
    "\n",
    "# upload_to_kaggle(\n",
    "#     [f[0] for f in EXP_FOLDERS],\n",
    "#     directory=\"../output/dataset_1/\",\n",
    "#     dataset_name=\"BirdCLEF 2024 Weights 1\",\n",
    "#     update_folders=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EVAL:\n",
    "    df = pd.DataFrame({\"path\": glob.glob(DATA_PATH + \"*/*\")})\n",
    "    df[\"id\"] = df[\"path\"].apply(lambda x: x.split(\"/\")[-1][:-4])\n",
    "\n",
    "    folds = pd.read_csv('../input/folds_4.csv')\n",
    "    folds['id'] = folds['filename'].apply(lambda x: x.split('/')[-1][:-4])\n",
    "    df = df.merge(folds)\n",
    "    df = df[df['fold'] == 0].reset_index(drop=True)\n",
    "\n",
    "    df[\"primary_label\"] = df[\"path\"].apply(lambda x:  x.split('/')[-2])\n",
    "\n",
    "    # cts = df[\"primary_label\"].value_counts()\n",
    "    # low_rep = list(cts[cts < 50].index)\n",
    "    # df = df[df[\"primary_label\"].isin(low_rep)].reset_index(drop=True)\n",
    "else:\n",
    "    df = pd.DataFrame({\"path\": glob.glob(DATA_PATH + \"*\")})\n",
    "    df[\"id\"] = df[\"path\"].apply(lambda x: x.split(\"/\")[-1][:-4])\n",
    "    \n",
    "    # df[\"duration\"] = df[\"path\"].apply(lambda x: librosa.get_duration(path=x))\n",
    "    # df = df[df[\"duration\"] == 240].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -> Loading encoder weights from ../logs/2024-06-09/10/efficientvit_b0_fullfit_0.pt\n",
      "\n",
      "\n",
      " -> Loading encoder weights from ../logs/2024-06-09/10/efficientvit_b0_fullfit_1.pt\n",
      "\n",
      "\n",
      " -> Loading encoder weights from ../logs/2024-06-09/10/efficientvit_b0_fullfit_2.pt\n",
      "\n",
      "\n",
      " -> Loading encoder weights from ../logs/2024-06-09/11/mnasnet_100_fullfit_0.pt\n",
      "\n",
      "\n",
      " -> Loading encoder weights from ../logs/2024-06-09/11/mnasnet_100_fullfit_1.pt\n",
      "\n",
      "\n",
      " -> Loading encoder weights from ../logs/2024-06-09/11/mnasnet_100_fullfit_2.pt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "for e in EXP_FOLDERS:\n",
    "    try:\n",
    "        exp_folder, folds, runtime = e\n",
    "    except:\n",
    "        exp_folder, folds = e\n",
    "        runtime = \"torch\"\n",
    "    \n",
    "    config = Config(json.load(open(exp_folder + \"config.json\", \"r\")))\n",
    "\n",
    "    for fold in folds:\n",
    "        weights = exp_folder + f\"{config.name}_{fold}.pt\"\n",
    "\n",
    "        model = define_model(\n",
    "            config.name,\n",
    "            config.melspec_config,\n",
    "            head=config.head,\n",
    "            aug_config=config.aug_config,\n",
    "            num_classes=config.num_classes,\n",
    "            n_channels=config.n_channels,\n",
    "            drop_rate=config.drop_rate,\n",
    "            drop_path_rate=config.drop_path_rate,\n",
    "            norm=config.norm if hasattr(config, \"norm\") else \"min_max\",\n",
    "            top_db=config.top_db if hasattr(config, \"top_db\") else None,\n",
    "            exportable=config.exportable,\n",
    "            verbose=True,\n",
    "            pretrained=False\n",
    "        )\n",
    "        model = model.to(DEVICE).eval()\n",
    "\n",
    "        model = load_model_weights(model, weights, verbose=config.local_rank == 0)\n",
    "        \n",
    "        models.append((model, runtime, (e[0], fold)))\n",
    "\n",
    "        if EVAL:\n",
    "            break\n",
    "\n",
    "sessions = [None for _ in range(len(models))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    batches = np.array_split(np.arange(len(df)), len(df) / 100)\n",
    "except:\n",
    "    batches = [np.arange(len(df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb7cca12c70f42e1aee2ccc001caaae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'idx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(batches)):\n\u001b[1;32m      4\u001b[0m     df_batch \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[batch]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../output/pl_final/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf_batch\u001b[38;5;241m.\u001b[39mid[\u001b[43midx\u001b[49m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_model_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m5\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     waves \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mParallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)(\n\u001b[1;32m     10\u001b[0m         joblib\u001b[38;5;241m.\u001b[39mdelayed(load_sample)(\n\u001b[1;32m     11\u001b[0m             path, evaluate\u001b[38;5;241m=\u001b[39mEVAL, sr\u001b[38;5;241m=\u001b[39mSR, duration\u001b[38;5;241m=\u001b[39mDURATION, normalize\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mwav_norm\n\u001b[1;32m     12\u001b[0m         )\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m df_batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     14\u001b[0m     )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'idx' is not defined"
     ]
    }
   ],
   "source": [
    "inference_rows = {i : [] for i in range(len(models))}\n",
    "\n",
    "for i, batch in enumerate(tqdm(batches)):\n",
    "    df_batch = df.iloc[batch].reset_index(drop=True)\n",
    "\n",
    "    waves = joblib.Parallel(n_jobs=4)(\n",
    "        joblib.delayed(load_sample)(\n",
    "            path, evaluate=EVAL, sr=SR, duration=DURATION, normalize=config.wav_norm\n",
    "        )\n",
    "        for path in df_batch[\"path\"].values\n",
    "    )\n",
    "\n",
    "    for model_idx in range(len(models)):\n",
    "        all_preds = [\n",
    "            infer_sample(\n",
    "                wave,\n",
    "                [models[model_idx][:2]],\n",
    "                sessions,\n",
    "                device=DEVICE,\n",
    "                use_fp16=USE_FP16,\n",
    "            )\n",
    "            for wave in waves\n",
    "        ]\n",
    "\n",
    "        for idx in range(len(df_batch)):\n",
    "            y_pred = all_preds[idx]\n",
    "            preds = expit(y_pred).mean(0)\n",
    "\n",
    "            for t, pred in enumerate(preds):\n",
    "                predictions = dict([(l, p) for l, p in zip(CLASSES, pred)])\n",
    "                inference_rows[model_idx].append(\n",
    "                    {\"row_id\": f\"{df_batch.id[idx]}_{(t + 1) * 5}\"} | predictions\n",
    "                )\n",
    "\n",
    "        del all_preds\n",
    "        gc.collect()\n",
    "    \n",
    "    del waves\n",
    "    gc.collect()\n",
    "\n",
    "    # break\n",
    "\n",
    "subs = {}\n",
    "for model_idx in range(len(models)):\n",
    "    sub = pd.DataFrame(inference_rows[model_idx])\n",
    "    name = models[model_idx][2][0] + f'pl_preds_{models[model_idx][2][1]}'\n",
    "\n",
    "    if not EVAL:\n",
    "        sub[[\"row_id\"]].to_csv(name + \".csv\", index=False)\n",
    "        np.save(name + \".npy\", sub[CLASSES].values)\n",
    "\n",
    "        print(f\"-> Saved predictions to {name}[.csv/.npy]\")\n",
    "        display(sub.head(2))\n",
    "\n",
    "        del (sub, inference_rows[model_idx])\n",
    "    else:\n",
    "        subs[name] = sub\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EVAL:\n",
    "    for k in subs.keys():\n",
    "        \n",
    "        exp = k.rsplit('/', 1)[0]\n",
    "        config = Config(json.load(open(exp + \"/config.json\", \"r\")))\n",
    "        model = config.name\n",
    "\n",
    "        print(f\"\\n -> Model {exp} - {model} - PL {config.use_pl} \\n\")\n",
    "\n",
    "        sub = subs[k]\n",
    "        preds = sub[CLASSES].values\n",
    "        max_ = preds.max(1)\n",
    "        auc, aucs = macro_auc(\n",
    "            df[\"primary_label\"].values.tolist()[: len(preds)],\n",
    "            preds,\n",
    "            return_per_class=True\n",
    "        )\n",
    "\n",
    "        print(f\"Fold 0 AUC: {auc:.5f}\\n\")\n",
    "\n",
    "        df_auc = pd.DataFrame({\"auc\": np.clip(list(aucs.values()), 0.5, 1), \"max\": preds.max(0)}, index=aucs.keys())\n",
    "        df_auc[\"count\"] = df_auc.index.map(cts)\n",
    "\n",
    "        df_auc = df_auc[df_auc.index.isin(low_rep)]\n",
    "\n",
    "        df_auc = df_auc.sort_values('auc').head(50)\n",
    "        display(df_auc.T)\n",
    "\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        sns.histplot(df_auc['auc'], bins=25, kde=True)\n",
    "        plt.xlim(0.5, 1)\n",
    "        plt.subplot(1, 3, 2)\n",
    "        sns.histplot(df_auc['max'], bins=25, kde=True)\n",
    "        plt.xlim(0., 1)\n",
    "\n",
    "        plt.subplot(1, 3, 3)\n",
    "\n",
    "        plt.scatter(df_auc[\"max\"], df_auc[\"auc\"], s=5)\n",
    "        plt.plot([-1, 2], [0, 1.5], c=\"salmon\")\n",
    "        plt.xlim(-0.01, 1.01)\n",
    "        plt.ylim(0.49, 1.01)\n",
    "\n",
    "        plt.show()\n",
    "        # break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "f7241b2af102f7e024509099765066b36197b195077f7bfac6e5bc041ba17c8c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
